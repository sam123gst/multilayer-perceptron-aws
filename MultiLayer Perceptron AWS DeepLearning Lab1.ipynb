{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies imported\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd\n",
    "print(\"Dependencies imported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a GPU with MXNet\n",
    "ctx = mx.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the MNIST image dataset\n",
    "mnist = mx.test_utils.get_mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the neural network\n",
    "\n",
    "# Number of inputs: A 1-dimensional input consisting of a single image (28 pixels by 28 pixels)\n",
    "num_inputs = 784\n",
    "\n",
    "# Number of Outputs: Number of outputs to be predicted by the network (Digits 0-9)\n",
    "num_outputs = 10\n",
    "\n",
    "# Batch size is the number of images processed in a single batch\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training data dn test data\n",
    "\n",
    "def transform(data, label):\n",
    "    return data.astype(np.float32)/255, label.astype(np.float32)\n",
    "\n",
    "train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=True, transform=transform),batch_size, shuffle=True)\n",
    "test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=False, transform=transform),batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hidden neurons\n",
    "num_hidden = 256\n",
    "\n",
    "# Weights scale\n",
    "weight_scale = .01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate weights and bias for the first layer\n",
    "w_hd_1 = nd.random_normal(shape=(num_inputs, num_hidden), scale=weight_scale, ctx=ctx)\n",
    "b_hd_1 = nd.random_normal(shape=num_hidden, scale=weight_scale, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate weights and bias for the second layer\n",
    "w_hd_2 = nd.random_normal(shape=(num_hidden, num_hidden), scale=weight_scale, ctx=ctx)\n",
    "b_hd_2 = nd.random_normal(shape=num_hidden, scale=weight_scale, ctx=ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate weights and bias for the output layer\n",
    "w_output = nd.random_normal(shape=(num_hidden, num_outputs), scale=weight_scale, ctx=ctx)\n",
    "b_output = nd.random_normal(shape=num_outputs, scale=weight_scale, ctx=ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parameters to calculate gradients\n",
    "params = [w_hd_1, b_hd_1, w_hd_2, b_hd_2, w_output, b_output]\n",
    "\n",
    "\n",
    "for param in params:\n",
    "    param.attach_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a ReLU activiation function for the hidden layer\n",
    "def relu(X):\n",
    "    return nd.maximum(X, nd.zeros_like(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a softmax action function for the output layer\n",
    "def softmax_cross_entropy(yhat_linear, y):\n",
    "    return - nd.nansum(y * nd.log_softmax(yhat_linear), axis=0, exclude=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model\n",
    "def net(X):\n",
    "\n",
    "    #  Compute the first hidden layer\n",
    "    h1_linear = nd.dot(X, w_hd_1) + b_hd_1\n",
    "    h1 = relu(h1_linear)\n",
    "\n",
    "    #  Compute the second hidden layer\n",
    "    h2_linear = nd.dot(h1, w_hd_2) + b_hd_2\n",
    "    h2 = relu(h2_linear)\n",
    "\n",
    "    #  Compute the output layer.\n",
    "    yhat_linear = nd.dot(h2, w_output) + b_output\n",
    "    return yhat_linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metric\n",
    "def evaluate_accuracy(data_iterator, net):\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        numerator += nd.sum(predictions == label)\n",
    "        denominator += data.shape[0]\n",
    "    return (numerator / denominator).asscalar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs are iterations over the full network\n",
    "epochs = 10\n",
    "\n",
    "# Learning rate parameter determines the speed at which the network learns\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Defining a smooth constant for the moving loss\n",
    "smoothing_constant = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 0.475494587297, Train_acc 0.8905, Test_acc 0.8912\n",
      "Epoch 1. Loss: 0.288055782388, Train_acc 0.924917, Test_acc 0.9249\n",
      "Epoch 2. Loss: 0.196092822246, Train_acc 0.948167, Test_acc 0.9474\n",
      "Epoch 3. Loss: 0.148628893256, Train_acc 0.962083, Test_acc 0.9584\n",
      "Epoch 4. Loss: 0.121844707697, Train_acc 0.96965, Test_acc 0.9642\n",
      "Epoch 5. Loss: 0.104030329089, Train_acc 0.974733, Test_acc 0.9678\n",
      "Epoch 6. Loss: 0.0832342584997, Train_acc 0.97825, Test_acc 0.9706\n",
      "Epoch 7. Loss: 0.0766369441815, Train_acc 0.9822, Test_acc 0.9718\n",
      "Epoch 8. Loss: 0.06376962288, Train_acc 0.983583, Test_acc 0.9743\n",
      "Epoch 9. Loss: 0.05726662875, Train_acc 0.986417, Test_acc 0.974\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network model\n",
    "for e in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(ctx)\n",
    "        label_one_hot = nd.one_hot(label, 10)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label_one_hot)\n",
    "        loss.backward()\n",
    "        SGD(params, learning_rate)\n",
    "\n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (curr_loss if ((i == 0) and (e == 0))\n",
    "                       else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_data, net)\n",
    "    train_accuracy = evaluate_accuracy(train_data, net)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" %\n",
    "          (e, moving_loss, train_accuracy, test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><head>\n",
       "<meta http-equiv=\"content-type\" content=\"text/html; charset=windows-1252\"><style type=\"text/css\">\n",
       "  canvas { border: 1px solid black; }\n",
       "</style>\n",
       "\n",
       "</head><body><div id=\"board\">\n",
       "\n",
       "  <canvas id=\"myCanvas\" width=\"100px\" height=\"100px\">\n",
       "    Sorry, your browser doesn't support canvas technology.\n",
       "  </canvas>\n",
       "\n",
       "  <p>\n",
       "\n",
       "    <button id=\"classify\" onclick=\"classify()\">\n",
       "      Classify\n",
       "    </button>\n",
       "\n",
       "    <button id=\"clear\" onclick=\"myClear()\">\n",
       "      Clear\n",
       "    </button>\n",
       "    Result:\n",
       "    <input id=\"result_output\" size=\"10\" type=\"text\">\n",
       "\n",
       "  </p>\n",
       "\n",
       "</div>\n",
       "\n",
       "<script type=\"text/JavaScript\" src=\"mnist_files/jquery.js\"> </script>\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "    function init() {\n",
       "        var myCanvas = document.getElementById(\"myCanvas\");\n",
       "        var curColor = $('#selectColor option:selected').val();\n",
       "        if (myCanvas) {\n",
       "            var isDown = false;\n",
       "            var ctx = myCanvas.getContext(\"2d\");\n",
       "            var canvasX, canvasY;\n",
       "            ctx.lineWidth = 8;\n",
       "            $(myCanvas).mousedown(function(e) {\n",
       "                isDown = true;\n",
       "                ctx.beginPath();\n",
       "                var parentOffset = $(this).parent().offset();\n",
       "                canvasX = e.pageX - parentOffset.left;\n",
       "                canvasY = e.pageY - parentOffset.top;\n",
       "                ctx.moveTo(canvasX, canvasY);\n",
       "            }).mousemove(function(e) {\n",
       "                if (isDown != false) {\n",
       "                    var parentOffset = $(this).parent().offset();\n",
       "                    canvasX = e.pageX - parentOffset.left;\n",
       "                    canvasY = e.pageY - parentOffset.top;\n",
       "                    ctx.lineTo(canvasX, canvasY);\n",
       "                    ctx.strokeStyle = curColor;\n",
       "                    ctx.stroke();\n",
       "                }\n",
       "            }).mouseup(function(e) {\n",
       "                isDown = false;\n",
       "                ctx.closePath();\n",
       "            });\n",
       "        }\n",
       "        $('#selectColor').change(function() {\n",
       "            curColor = $('#selectColor option:selected').val();\n",
       "        });\n",
       "    }\n",
       "init();\n",
       "\n",
       "function handle_output(out) {\n",
       "    for (var name in out.content.traceback) {\n",
       "      console.log(out.content.traceback);\n",
       "    }\n",
       "    console.log('this is out' + out.content.data[\"text/plain\"])\n",
       "    document.getElementById(\"result_output\").value = out.content.data[\"text/plain\"];\n",
       "}\n",
       "\n",
       "function classify() {\n",
       "    var kernel = IPython.notebook.kernel;\n",
       "    var myCanvas = document.getElementById(\"myCanvas\");\n",
       "    console.log(myCanvas)\n",
       "    data = myCanvas.toDataURL('image/png');\n",
       "    console.log(data)\n",
       "    document.getElementById(\"result_output\").value = \"\";\n",
       "    console.log(\"classify('\" + data + \"')\", {\n",
       "        'iopub': {\n",
       "            'output': handle_output\n",
       "        }\n",
       "    }, {\n",
       "        silent: false\n",
       "    })\n",
       "    kernel.execute(\"classify('\" + data + \"')\", {\n",
       "        'iopub': {\n",
       "            'output': handle_output\n",
       "        }\n",
       "    }, {\n",
       "        silent: false\n",
       "    });\n",
       "}\n",
       "\n",
       "function myClear() {\n",
       "    var myCanvas = document.getElementById(\"myCanvas\");\n",
       "    myCanvas.getContext(\"2d\").clearRect(0, 0, myCanvas.width, myCanvas.height);\n",
       "}\n",
       "\n",
       "\n",
       "</script>\n",
       "</body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an HTML canvas to evaluate the model\n",
    "from IPython.display import HTML\n",
    "import cv2\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "def classify(img):\n",
    "    img = base64.b64decode(img[len('data:image/png;base64,'):])\n",
    "    img = cv2.imdecode(np.fromstring(img, np.uint8),-1)\n",
    "    img = cv2.resize(img[:,:,3], (28,28))\n",
    "    img = nd.array(img).as_in_context(ctx).reshape((-1, 784)).astype(np.float32)/255\n",
    "    return int(nd.argmax(net(img), axis=1).asnumpy()[0])\n",
    "\n",
    "HTML(filename = \"mnist.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
